{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置Tensorflow\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"7\"\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据集\n",
    "mnist=tf.keras.datasets.mnist\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train,x_test=x_train/255.0,x_test/255.0 #将样本数据从整数转换为浮点数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\youyiting\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#通过堆叠层来构建机器学习模型\n",
    "model=tf.keras.models.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(28,28)),#该层次将数据从二维数组展平成一维数组\n",
    "tf.keras.layers.Dense(128,activation=\"relu\"),#这是一个全连接层，具有128个神经元和ReLU激活函数\n",
    "tf.keras.layers.Dropout(0.2),#这个层在训练过程中随机丢弃一部分神经元的激活值，丢弃比例为20%(0.2),以减少过拟合\n",
    "tf.keras.layers.Dense(10)#模型的输出层，有10个神经元，这通常对应于分类任务中的类别数量\n",
    "])#线性堆叠的层次模型，用于快速构建一个前馈神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13478138, -0.03413622, -0.5517986 , -0.35491657, -0.24875826,\n",
       "        -1.0369924 , -0.5020624 ,  0.4550425 , -0.2794225 ,  0.69409925]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12093743, 0.10214116, 0.06086714, 0.07411186, 0.08241223,\n",
       "        0.03746846, 0.06397099, 0.16658981, 0.07992348, 0.21157749]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将logits转换为每个类的概率\n",
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 losses.SparseCategoricalCrossentropy 为训练定义损失函数，它会接受 \n",
    "\n",
    "logits 向量和 True 索引，并为每个样本返回一个标量损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.284256"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#配置和编译模型\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=loss_fn,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 946us/step - accuracy: 0.9784 - loss: 0.0686\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 933us/step - accuracy: 0.9819 - loss: 0.0568\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 937us/step - accuracy: 0.9836 - loss: 0.0493\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 987us/step - accuracy: 0.9843 - loss: 0.0476\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 966us/step - accuracy: 0.9854 - loss: 0.0440\n",
      "313/313 - 0s - 624us/step - accuracy: 0.9794 - loss: 0.0715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07149577885866165, 0.9793999791145325]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练和评估模型\n",
    "model.fit(x_train,y_train,epochs=5)\n",
    "model.evaluate(x_test,y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果想让模型返回概率值,可以封装经过训练的模型，并将softmax附加到该模型\n",
    "probability_model=tf.keras.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1.84347682e-09, 5.45483880e-10, 2.25658880e-07, 2.84735252e-05,\n",
       "        8.91369281e-13, 3.54000695e-09, 1.48560960e-17, 9.99971151e-01,\n",
       "        6.95553448e-10, 1.36723159e-07],\n",
       "       [5.94566443e-13, 1.49390260e-07, 9.99999642e-01, 2.42805527e-07,\n",
       "        7.86597306e-21, 1.41632206e-09, 4.55461580e-12, 1.55312815e-19,\n",
       "        1.30194300e-09, 5.26332388e-22],\n",
       "       [2.44133402e-09, 9.99902248e-01, 5.66152630e-06, 4.86098656e-07,\n",
       "        1.54220771e-07, 2.21087447e-07, 3.32548507e-06, 6.29887509e-05,\n",
       "        2.47845528e-05, 4.50443594e-09],\n",
       "       [9.99272764e-01, 1.58576541e-10, 6.68505572e-06, 9.48077616e-09,\n",
       "        2.37134699e-07, 3.58454599e-07, 7.14181457e-04, 3.64956527e-08,\n",
       "        6.30592778e-09, 5.81887298e-06],\n",
       "       [1.19908954e-08, 7.76896741e-11, 6.28069197e-09, 1.08912435e-10,\n",
       "        9.98656631e-01, 6.40681552e-09, 2.00828197e-07, 1.55512625e-05,\n",
       "        1.14828955e-08, 1.32760825e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
